\section{Outline of the Problem}
\label{sec:theory-outline}
By applying the theory of \ac{NMR}, one can
rationalise how a particular spin system, subjected to a given pulse sequence,
is mapped to \iac{FID}. This is an example of a \emph{forward problem},
in which one wishes to determine how a set of parameters leads to an
observed dataset.
The chemical shifts, J-couplings, dipolar couplings, etc. of the spin system
may be recast as a list of signal amplitudes, phases, frequencies and
damping factors, which define the form that the \ac{FID} is expected to take.
Sophisticated pieces of software such as \textsc{Spinach}~\cite{Hogben2011}
solve this forward problem, yielding \ac{NMR} experiment simulations.
Simulating an \ac{NMR} experiment is a \emph{well-posed} problem, since it
satisfies the following properties:
\begin{enumerate}
    \item The problem has a solution.
    \item The solution is unique.
    \item The solution's behaviour changes continuously with the parameters
        provided. For example, continuously changing the chemical shift of a
        given spin will lead to the position(s) of the signal(s) arising from
        it in the resulting spectrum to continuously vary. Other phenomena such
        as strong coupling effects may manifest as a given spin's chemical
        shift changes; these will evolve in a continuous fashion as well.
\end{enumerate}
The estimation of \acp{FID} is an example of an \emph{inverse problem};
given an acquired dataset, the objective is to determine the set of parameters
which went into constructing it.
As with many inverse problems, \ac{FID} estimation is
\emph{ill-posed}~\cite{Kabanikhin2008}; such problems do not satisfy at least
one of the three properties above. For example, given \iac{FID}, it is possible
to conceive of numerous signal parameter specifications which would lead to a
faithful representation of the data in a least squares sense, especially when
considering \acp{FID} corrupted with noise which comprise signals of similar
frequencies. Therefore, determining the ``optimal'' parameter set is a rather
difficult challenge.

For the purposes of this work, it is always assumed that an \ac{FID} to be
estimated
$\bY \in \mathbb{C}^{\None \times \cdots \times \ND}$
is hypercomplex in form, meaning that it obeys
\cref{eq:general-fid} with $\zeta^{(d)} = \exp(\iu \cdot)\ \forall d \in
\lbrace 1, \cdots, D \rbrace$:
\begin{subequations}
    \begin{gather}
        \ynonenD = \xnonenD(\bth) + \wnonenD,\\
        \xnonenD(\bth) =
        \sumM \amexpphim
        \prodD \exp\left(\left(
            2 \pi \iu \left(f^{(d)}_m - \foffd\right)
            -\eta_m^{(d)}\right)
            \nd \Dtd\right),\label{eq:x}\\
        \wnonenD \sim \mathcal{N_C}\left(0, 2\sigma^2\right),%
        \label{eq:complex-normal}
    \end{gather}%
    \label{eq:hypercomplex-fid}%
\end{subequations}%
where $\Dtd = \nicefrac{1}{\fswd}$.
Alternatively, \cref{eq:x} may be expressed in terms of complex amplitudes and
signals poles as follows:
\begin{subequations}%
    \begin{gather}%
        \xnonenD(\bth) = \sumM \alpha_m \prodD {z^{(d)}_m}^{\nd},\\
        \alpha_m = \amexpphim,\\
        z_m^{(d)} = \exp\left(
            \left(2 \pi \iu \left(f_m^{(d)} - \foffd\right) - \eta^{(d)}_m\right) \Dtd
        \right).%
    \end{gather}%
    \label{eq:x-alpha-z}%
\end{subequations}%
Under this model, it is assumed that
\iac{FID} consists of a summation of $M$ damped complex sinusoids in the
presence in \ac{AWGN}.
It should be noted that, prior to estimating the dataset, it is normalised
such that the signal actually under consideration is $\nicefrac{\bY}{\lVert \bY
\rVert}$.
To make the final result reflect the unnormalised dataset, the estimated
amplitudes can be multiplied by $\lVert \symbf{Y} \rVert$.

It is the goal of parametric estimation to establish the
identity of all the quantities that describe the model component $\bX$, which
are distilled into the vector $\bth \in \mathbb{R}^{2(D + 1)M}$, given by
\cref{eq:theta}.
Due to the assumed \ac{AWGN} nature of the noise array, the
\ul{probability density functions (PDFs)}\acused{PDF} of the
\correction{
    real and imaginary components of an individual noise element are the
    following (in accordance with \cref{eq:complex-normal}):
    \begin{subequations}
        \begin{gather}
            p\left(\Re\left(\wnonenD\right)\right) =
                \frac{1}{\sqrt{2\pi \sigma^2}}
                \exp\left( -\frac{\Re\left(\wnonenD\right)^2}{2\pi\sigma^2}\right),
                \label{eq:PDF-real}\\
            p\left(\Im\left(\wnonenD\right)\right) =
                \frac{1}{\sqrt{2\pi \sigma^2}}
                \exp\left( -\frac{\Im\left(\wnonenD\right)^2}{2\pi\sigma^2}\right).
                \label{eq:PDF-imag}
        \end{gather}%
        \label{eq:prob-density}%
    \end{subequations}
The real and imaginary noise elements are acquired under the same
conditions, such that \cref{eq:PDF-real,eq:PDF-imag} are identical.
Hence\footnote{
    \correction{N.B.
    $\left\lvert \wnonenD \right\rvert^2 \equiv \Re\left(\wnonenD\right)^2 + \Im\left(\wnonenD\right)^2$
    }
}:
\begin{equation}
    p\left(\wnonenD\right) =
        \frac{1}{2\pi \sigma^2}
        \exp\left( -\frac{\left\lvert\wnonenD\right\rvert^2}{2\pi\sigma^2}\right),%
\end{equation}%
}\label{corr:complex-normal}%
As the noise components are assumed to be independent and identically
distributed, the joint \ac{PDF} describing the entire noise array is given by
the product of the \acp{PDF} of all the components:
\begin{equation}
    \begin{split}
        p\left(\bW\right) &=
            \prod_{\none=0}^{\None - 1}
            \cdots
            \prod_{\nD=0}^{\ND - 1}
            \frac{1}{2\pi \sigma^2}
            \exp\left(
                -\frac
                {\left\lvert \wnonenD \right\rvert^2}
                {2\sigma^2}\right) \\
            &= \frac{1}{\left(2\pi \sigma^2\right)^{N_{\text{tot}}}}
            \exp\left( -\frac{\left\lVert \bW \right\rVert^2}{2\sigma^2}\right),
    \end{split}
\end{equation}
where $N_{\text{tot}} \coloneq \None \times \cdots \times \ND$.
By noting that the noise array is the difference between the data and model,
the \ul{likelihood function} of $\bth$ given the \ac{FID} $\bY$ is
\begin{equation}
    \mathcal{L}(\bth \vert \bY) =
        \frac{1}{\left(2\pi \sigma^2\right)^{N_{\text{tot}}}}
        \exp\left( -\frac{\left\lVert \bY - \bX(\bth) \right\rVert^2}{2\sigma^2}\right).
\end{equation}
It is common to consider instead the log-likelihood function,
$\ell(\bth \vert \bY) \coloneq \ln \mathcal{L}(\bth \vert
\bY)$:
\begin{equation}
\ell(\bth \vert \bY) =
-N_{\text{tot}} \ln\left(2 \pi \sigma^2\right)
-\frac{\left\lVert \bY - \bX(\bth) \right\rVert^2}{2\sigma^2}.
\label{eq:log-likeihood}
\end{equation}
As the application of the logarithm is a monotonic transformation, the
arguments of the maxima of $\mathcal{L}$ and $\ell$ are equivalent.
\Cref{eq:log-likeihood} implies that the optimal set of parameters
$\bth^{(*)}$, i.e. the \ac{MLE},
is that which minimises the \ac{RSS} between the data and the model:
\begin{equation}
\bthstar = \argmax_{\bth \in \mathbb{R}^{2(D+1)M}}
\ell\left(\bth \vert \bY\right) \equiv
\argmin_{\bth \in \mathbb{R}^{2(D+1)M}} \left\lVert \bY - \bX(\bth) \right\rVert^2.
\label{eq:argmin_y-x}
\end{equation}
The application of \ac{NLP} is a well-established approach to solve such a
problem~\cite{Nocedal2006,Fletcher1987}. The basic principle behind \ac{NLP} is
to iteratively explore, in a methodical way, how a function varies with its
arguments. By using information about the function and optionally its
derivatives, such a routine attempts to find a minimum in the function, and
terminates once this has been achieved. While derivative-free approaches to
\ac{NLP} do exist~\cite{Nelder1965,Kirkpatrick1983,Powell2009},
in scenarios where the function under consideration has well-defined,
computationally tractable derivatives, the use of these can be valuable when
solving optimisation problems; the problem outlined in
\cref{eq:argmin_y-x} is such an example.

As discussed already, for \ac{NLP} to perform effectively, a large amount of
\textit{a priori} information is typically required, in the form of an initial
guess, possibly alongside other constraints. To achieve this, the method
employed in this work makes use of the \ac{MPM}, the subject of the next
section.
